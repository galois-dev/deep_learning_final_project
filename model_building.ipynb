{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "1. Load images\n",
    "2. Resize images to 256 x 256\n",
    "3. Save images as tensors\n",
    "\n",
    "<span style=\"color:red\"> Why did we only choose to resize images rather than normalizing them? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size to resize to\n",
    "IMAGE_SIZE = [256,256]\n",
    "\n",
    "# Load and resize images\n",
    "class DataLoader(Dataset):\n",
    "\n",
    "    def __init__(self, _path, transform=True):\n",
    "\n",
    "        # Path of where data is located\n",
    "        self._path = _path\n",
    "        self.monets = os.listdir(_path + \"/monet_jpg\")\n",
    "        self.photos = os.listdir(_path + \"/photo_jpg\")\n",
    "\n",
    "        # Memorize path indices for later\n",
    "        self.monet_indices = dict()\n",
    "        self.photo_indices = dict()\n",
    "\n",
    "        ## Add indices to dictionary\n",
    "        for i, fl in enumerate(self.monets):\n",
    "            self.monet_indices[i] = fl\n",
    "        for i, fl in enumerate(self.photos):\n",
    "            self.photo_indices[i] = fl\n",
    "\n",
    "        # Resize images and save as a tensor\n",
    "        if transform:\n",
    "            # Default 0-1 norm\n",
    "            self.transform = transforms.Compose((\n",
    "                transforms.Resize(IMAGE_SIZE, antialias=False),\n",
    "                transforms.ToTensor(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Helper function to get length of dataset\n",
    "    def __len__(self):\n",
    "        return min(len(self.monets), len(self.photos))\n",
    "\n",
    "    # Helper function to return example images\n",
    "    def __getitem__(self, index):\n",
    "        random_index = int(np.random.uniform(0, len(self.monet_indices.keys())))\n",
    "        monet_src = Image.open(os.path.join(self._path, \"monet_jpg\", self.monet_indices[index % 300]))   \n",
    "        photo_src = Image.open(os.path.join(self._path, \"photo_jpg\", self.photo_indices[random_index]))\n",
    "        monet_src = self.transform(monet_src)\n",
    "        photo_src = self.transform(photo_src)\n",
    "        return photo_src, monet_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = DataLoader(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Normalization\n",
    "[Weight Normalization: A Simple Reparameterization\n",
    "to Accelerate Training of Deep Neural Networks\n",
    "](https://arxiv.org/pdf/1602.07868)\n",
    "\n",
    "A reparametrization method that separates the magnitude of the weight tensor from its direction $\\to$ **speeds up convergence**!\n",
    "\n",
    "<span style='color:red'> Where is the superclass ***WeightNormlization*** from? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class using pre-existing superclass?\n",
    "class WeightNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, epsilon=1e-6):\n",
    "        super(WeightNormalization, self).__init__()\n",
    "\n",
    "        # Instantiate random weights\n",
    "        self.weights = nn.Parameter(torch.randn(in_channels)) \n",
    "\n",
    "        # Define \n",
    "        self.scaling = nn.Parameter(torch.ones(in_channels)) \n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        unsqueezed = False\n",
    "        if x.dim() == 3: \n",
    "            x = x.unsqueeze(0) \n",
    "            unsqueezed = True\n",
    "        norm = torch.sqrt(torch.sum(x**2, dim=(2, 3), keepdim=True) + self.epsilon)\n",
    "        scaled = x / norm\n",
    "        scaled = scaled * self.scaling.view(\n",
    "            1, -1, 1, 1\n",
    "        ) \n",
    "        if unsqueezed:  \n",
    "            scaled = scaled.squeeze(0)\n",
    "\n",
    "        return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
